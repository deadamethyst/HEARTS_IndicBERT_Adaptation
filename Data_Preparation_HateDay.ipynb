{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b37d19f",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b486072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "import pandas as pd\n",
    "from huggingface_hub import login\n",
    "import sentencepiece\n",
    "import accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, AlbertTokenizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0020d81",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204015c",
   "metadata": {},
   "source": [
    "The dataset we are using is not publically available. You need to request the authors, to access this dataset\n",
    "\n",
    "Name of Datset: HateDay, a global hate speech dataset  \n",
    "Source: Tonneau et al. (2025), arXiv:2411.15462  \n",
    "Available at: https://arxiv.org/abs/2411.15462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884db5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f617385b8e491199b10d6d9431bfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  labels\n",
      "0      वक्त, इन्सान और इंग्लैंड का मौसम आपको कभी भी ध...       0\n",
      "1      #कांग्रेस के इस #कमीने की #करतूत को देखिए देश ...       0\n",
      "2      पाकिस्तान को फेकना था फेका गया। जो हार कर भी द...       0\n",
      "3      जो शब्द तूम आज किसी और औरत के लिए यूज कर रहे व...       0\n",
      "4      नेता जी हम समाजवादी सिपाही हमेशा आपके साथ है आ...       0\n",
      "...                                                  ...     ...\n",
      "14150  सोनू सूद से प्रेरणा लेकर आदिवासियों ने वो किया...       0\n",
      "14151  RT @USER: उमर खालिद पर तो UAPA लगा दिया!\\nकपिल...       1\n",
      "14152                                  @USER पप्पू कमीना       0\n",
      "14153  मदर टेरेसा ने अपना पूरा जीवन पीड़ितों की सेवा ...       0\n",
      "14154  आईपीएल में कोरोना का डर: रैना के हटने के बाद ह...       0\n",
      "\n",
      "[14155 rows x 2 columns]\n",
      "\n",
      " Datset loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Logging in Hugging Face\n",
    "login()\n",
    "\n",
    "# Loading dataset directly from HuggingFace Hub\n",
    "dataset = load_dataset(\"manueltonneau/india-hate-speech-superset\")\n",
    "\n",
    "# Converting the HF dataset split into a pandas DataFrame\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Keeping only text + labels columns\n",
    "df = df[[\"text\", \"labels\"]].copy()\n",
    "\n",
    "# Printing confirmation\n",
    "print(df)\n",
    "print(\"\\n Datset loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5b871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels', 'source', 'dataset', 'nb_annotators'],\n",
      "        num_rows: 14155\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Print available splits\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c92afa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataframe shape: (14155, 2)\n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14155 entries, 0 to 14154\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    14155 non-null  object\n",
      " 1   labels  14155 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 221.3+ KB\n",
      "None\n",
      "\n",
      "Label distribution (raw):\n",
      "labels\n",
      "0    12281\n",
      "1     1874\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Basic overview of the dataset\n",
    "print(\"Initial dataframe shape:\", df.shape)\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nLabel distribution (raw):\")\n",
    "print(df[\"labels\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96613459",
   "metadata": {},
   "source": [
    "# Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476be6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to clean the dataset\n",
    "def clean_hindi_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Very light cleaning of a Hindi / code-mixed string.\n",
    "    - Lowercases Latin characters (does NOT touch Devanagari).\n",
    "    - Removes URLs.\n",
    "    - Removes @usernames.\n",
    "    - Strips leading '#' but keeps the hashtag word (for both Latin & Hindi).\n",
    "    - Normalises multiple spaces.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # Removing URLs\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "    \n",
    "    # Removing @usernames (any non-space after @)\n",
    "    text = re.sub(r\"@[^\\s]+\", \" \", text)\n",
    "    \n",
    "    # Stripping '#' but keeping the following token (Latin or Hindi)\n",
    "    # e.g. \"#कांग्रेस\" becomes \"कांग्रेस\", \"#Modi\" becomes \"Modi\" after cleaning\n",
    "    text = re.sub(r\"#(\\S+)\", r\"\\1\", text)\n",
    "    \n",
    "    # lowercase Latin letters only\n",
    "    text = \"\".join(\n",
    "        ch.lower() if \"A\" <= ch <= \"Z\" or \"a\" <= ch <= \"z\" else ch\n",
    "        for ch in text\n",
    "    )\n",
    "    \n",
    "    # Collapsing multiple whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db9379f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>वक्त, इन्सान और इंग्लैंड का मौसम आपको कभी भी ध...</td>\n",
       "      <td>वक्त, इन्सान और इंग्लैंड का मौसम आपको कभी भी ध...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#कांग्रेस के इस #कमीने की #करतूत को देखिए देश ...</td>\n",
       "      <td>कांग्रेस के इस कमीने की करतूत को देखिए देश की ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>पाकिस्तान को फेकना था फेका गया। जो हार कर भी द...</td>\n",
       "      <td>पाकिस्तान को फेकना था फेका गया। जो हार कर भी द...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>जो शब्द तूम आज किसी और औरत के लिए यूज कर रहे व...</td>\n",
       "      <td>जो शब्द तूम आज किसी और औरत के लिए यूज कर रहे व...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>नेता जी हम समाजवादी सिपाही हमेशा आपके साथ है आ...</td>\n",
       "      <td>नेता जी हम समाजवादी सिपाही हमेशा आपके साथ है आ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@USER @USER @USER @USER @USER #AayegaTohModiHi...</td>\n",
       "      <td>aayegatohmodihi bjp4india bjp कन्हैया_कुमार ने...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#कुत्ते भी हो रहे हैं #किडनी और #डायबटीज जैसी ...</td>\n",
       "      <td>कुत्ते भी हो रहे हैं किडनी और डायबटीज जैसी बीम...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VIVAHIT BaitION KO BHI Patrick KIRSI BHOOMI MA...</td>\n",
       "      <td>vivahit baition ko bhi patrick kirsi bhoomi ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10 एजेंसियों को किसी भी कंप्यूटर की निगरानी और...</td>\n",
       "      <td>10 एजेंसियों को किसी भी कंप्यूटर की निगरानी और...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>कश्मीर मे सेना पर पत्थर मारने वाले और पत्थरबाज...</td>\n",
       "      <td>कश्मीर मे सेना पर पत्थर मारने वाले और पत्थरबाज...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>झोंपड़ी के, कुछ दिन पहले तक तो तू उस आदतन 'बाइ...</td>\n",
       "      <td>झोंपड़ी के, कुछ दिन पहले तक तो तू उस आदतन 'बाइ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>अभी सूअर 6 महीने में दिल्ली में विधानसभा चुनाव...</td>\n",
       "      <td>अभी सूअर 6 महीने में दिल्ली में विधानसभा चुनाव...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>कुछ कमीने #नीच ग्रह में पैदा होते है और वो पैद...</td>\n",
       "      <td>कुछ कमीने नीच ग्रह में पैदा होते है और वो पैदा...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>भाई जैसे दिल्ली मे चुनाव आएगा हिन्दू-मुस्लिम क...</td>\n",
       "      <td>भाई जैसे दिल्ली मे चुनाव आएगा हिन्दू-मुस्लिम क...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pakode talna chalu kr do... mudra scheme se pa...</td>\n",
       "      <td>pakode talna chalu kr do... mudra scheme se pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>बेटा धोनी के बारे में कुछ बुरा बोले ना तो  क्र...</td>\n",
       "      <td>बेटा धोनी के बारे में कुछ बुरा बोले ना तो क्रि...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>आदरणीय राष्ट्रीय अध्यक्ष जी से विनम्र निवेदन ह...</td>\n",
       "      <td>आदरणीय राष्ट्रीय अध्यक्ष जी से विनम्र निवेदन ह...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>देश के #अंदरूनी_दुश्मन_राहुल_गांधी से  निपटने ...</td>\n",
       "      <td>देश के अंदरूनी_दुश्मन_राहुल_गांधी से निपटने के...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>भाई UP में राम राज्य उबाल मार रहा है? हैवानियत...</td>\n",
       "      <td>भाई up में राम राज्य उबाल मार रहा है? हैवानियत...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>संत कबीर डिग्रीधारी नहीं थे लेकिन धार्मिक आडंब...</td>\n",
       "      <td>संत कबीर डिग्रीधारी नहीं थे लेकिन धार्मिक आडंब...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   वक्त, इन्सान और इंग्लैंड का मौसम आपको कभी भी ध...   \n",
       "1   #कांग्रेस के इस #कमीने की #करतूत को देखिए देश ...   \n",
       "2   पाकिस्तान को फेकना था फेका गया। जो हार कर भी द...   \n",
       "3   जो शब्द तूम आज किसी और औरत के लिए यूज कर रहे व...   \n",
       "4   नेता जी हम समाजवादी सिपाही हमेशा आपके साथ है आ...   \n",
       "5   @USER @USER @USER @USER @USER #AayegaTohModiHi...   \n",
       "6   #कुत्ते भी हो रहे हैं #किडनी और #डायबटीज जैसी ...   \n",
       "7   VIVAHIT BaitION KO BHI Patrick KIRSI BHOOMI MA...   \n",
       "8   10 एजेंसियों को किसी भी कंप्यूटर की निगरानी और...   \n",
       "9   कश्मीर मे सेना पर पत्थर मारने वाले और पत्थरबाज...   \n",
       "10  झोंपड़ी के, कुछ दिन पहले तक तो तू उस आदतन 'बाइ...   \n",
       "11  अभी सूअर 6 महीने में दिल्ली में विधानसभा चुनाव...   \n",
       "12  कुछ कमीने #नीच ग्रह में पैदा होते है और वो पैद...   \n",
       "13  भाई जैसे दिल्ली मे चुनाव आएगा हिन्दू-मुस्लिम क...   \n",
       "14  Pakode talna chalu kr do... mudra scheme se pa...   \n",
       "15  बेटा धोनी के बारे में कुछ बुरा बोले ना तो  क्र...   \n",
       "16  आदरणीय राष्ट्रीय अध्यक्ष जी से विनम्र निवेदन ह...   \n",
       "17  देश के #अंदरूनी_दुश्मन_राहुल_गांधी से  निपटने ...   \n",
       "18  भाई UP में राम राज्य उबाल मार रहा है? हैवानियत...   \n",
       "19  संत कबीर डिग्रीधारी नहीं थे लेकिन धार्मिक आडंब...   \n",
       "\n",
       "                                         cleaned_text  labels  \n",
       "0   वक्त, इन्सान और इंग्लैंड का मौसम आपको कभी भी ध...       0  \n",
       "1   कांग्रेस के इस कमीने की करतूत को देखिए देश की ...       0  \n",
       "2   पाकिस्तान को फेकना था फेका गया। जो हार कर भी द...       0  \n",
       "3   जो शब्द तूम आज किसी और औरत के लिए यूज कर रहे व...       0  \n",
       "4   नेता जी हम समाजवादी सिपाही हमेशा आपके साथ है आ...       0  \n",
       "5   aayegatohmodihi bjp4india bjp कन्हैया_कुमार ने...       0  \n",
       "6   कुत्ते भी हो रहे हैं किडनी और डायबटीज जैसी बीम...       0  \n",
       "7   vivahit baition ko bhi patrick kirsi bhoomi ma...       1  \n",
       "8   10 एजेंसियों को किसी भी कंप्यूटर की निगरानी और...       1  \n",
       "9   कश्मीर मे सेना पर पत्थर मारने वाले और पत्थरबाज...       0  \n",
       "10  झोंपड़ी के, कुछ दिन पहले तक तो तू उस आदतन 'बाइ...       0  \n",
       "11  अभी सूअर 6 महीने में दिल्ली में विधानसभा चुनाव...       1  \n",
       "12  कुछ कमीने नीच ग्रह में पैदा होते है और वो पैदा...       0  \n",
       "13  भाई जैसे दिल्ली मे चुनाव आएगा हिन्दू-मुस्लिम क...       0  \n",
       "14  pakode talna chalu kr do... mudra scheme se pa...       0  \n",
       "15  बेटा धोनी के बारे में कुछ बुरा बोले ना तो क्रि...       0  \n",
       "16  आदरणीय राष्ट्रीय अध्यक्ष जी से विनम्र निवेदन ह...       0  \n",
       "17  देश के अंदरूनी_दुश्मन_राहुल_गांधी से निपटने के...       0  \n",
       "18  भाई up में राम राज्य उबाल मार रहा है? हैवानियत...       0  \n",
       "19  संत कबीर डिग्रीधारी नहीं थे लेकिन धार्मिक आडंब...       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the cleaning fucntion and creating a new column, \"cleaned_text\"\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(clean_hindi_text)\n",
    "\n",
    "# Checking rows after cleaning\n",
    "df[[\"text\", \"cleaned_text\", \"labels\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be7cd238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14155, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a505f47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows BEFORE dropping duplicates:     14155\n",
      "Exact duplicates (by 'text'):        28\n",
      "Rows AFTER dropping duplicates:      14127\n",
      "Rows removed:                        28\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate tweets based on uncleaned datsaet column, \"text\"\n",
    "# Before\n",
    "rows_before = len(df)\n",
    "\n",
    "# Boolean mask: True for rows that are duplicates of an earlier row \n",
    "dup_mask_text = df.duplicated(subset=[\"text\"])\n",
    "n_dups_text = dup_mask_text.sum()\n",
    "\n",
    "print(f\"Rows BEFORE dropping duplicates:     {rows_before}\")\n",
    "print(f\"Exact duplicates (by 'text'):        {n_dups_text}\")\n",
    "\n",
    "# Dropping only those duplicates (keep the first occurrence)\n",
    "df = df[~dup_mask_text].reset_index(drop=True)\n",
    "\n",
    "rows_after = len(df)\n",
    "print(f\"Rows AFTER dropping duplicates:      {rows_after}\")\n",
    "print(f\"Rows removed:                        {rows_before - rows_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f92ab16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset summary:\n",
      "Shape: (14127, 3)\n",
      "\n",
      "Label distribution (labels):\n",
      "labels\n",
      "0    12257\n",
      "1     1870\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution by cleaned_text length:\n",
      "count    14127.000000\n",
      "mean       147.298790\n",
      "std         83.962405\n",
      "min          0.000000\n",
      "25%         89.000000\n",
      "50%        126.000000\n",
      "75%        201.000000\n",
      "max       2281.000000\n",
      "Name: cleaned_len, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Basic sanity checks\n",
    "print(\"\\nFinal dataset summary:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nLabel distribution (labels):\")\n",
    "print(df[\"labels\"].value_counts())\n",
    "\n",
    "print(\"\\nLabel distribution by cleaned_text length:\")\n",
    "df[\"cleaned_len\"] = df[\"cleaned_text\"].str.len()\n",
    "print(df[\"cleaned_len\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67873fdb",
   "metadata": {},
   "source": [
    "# Saving the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74b4c639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved cleaned dataset for model training to: hindi_hatespeech_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Keeping both original 'text'\n",
    "# And 'cleaned_text' as the actual model input.\n",
    "final_df = df[[\"text\", \"cleaned_text\", \"labels\"]].copy()\n",
    "\n",
    "# Saving to CSV in current directory\n",
    "output_csv = \"hindi_hatespeech_cleaned.csv\"\n",
    "final_df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n Saved cleaned dataset for model training to: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
