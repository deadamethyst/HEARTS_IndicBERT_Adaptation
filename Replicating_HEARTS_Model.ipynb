{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba20d180",
   "metadata": {},
   "source": [
    "# Importing and Installing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb000be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "\n",
    "# Defining packages to be installed \n",
    "pkgs = [\n",
    "    \"torch\",\n",
    "    \"transformers==4.48.0\",\n",
    "    \"datasets\",\n",
    "    \"accelerate\",\n",
    "    \"scikit-learn\",\n",
    "    \"pandas\",\n",
    "    \"numpy\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\"\n",
    "]\n",
    "\n",
    "# Installing packages\n",
    "for p in pkgs:\n",
    "    print(\"Installing\", p)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", p])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a71fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GPU VERIFICATION\n",
      "============================================================\n",
      "Python version: 3.10.19\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU count: 1\n",
      "GPU name: Tesla T4\n",
      "GPU memory: 15.64 GB\n",
      "\n",
      "‚úÖ GPU is available and ready!\n"
     ]
    }
   ],
   "source": [
    "# VERIFYING GPU ACCESS\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(\"\\n‚úÖ GPU is available and ready!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå NO GPU DETECTED - Training will be very slow!\")\n",
    "    print(\"Check your kernel/runtime settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39d71d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (25.3)\n",
      "Requirement already satisfied: sentencepiece==0.1.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "# Installing sentencepiece(required for Explainability tasks)\n",
    "!pip install -U pip\n",
    "!pip install \"sentencepiece==0.1.99\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767d9a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "IMPORTING LIBRARIES\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Importing all libraries\n",
    "\n",
    "# Core libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Transformers and datasets\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Sklearn metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    precision_recall_fscore_support, \n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9498029",
   "metadata": {},
   "source": [
    "# Setting up Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52532ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SETTING UP WORKING DIRECTORY\n",
      "============================================================\n",
      "Working directory: /home/ec2-user/HEARTS_Replication\n",
      "Output directory:  /home/ec2-user/HEARTS_Replication/model_output_albertv2\n",
      "Results directory: /home/ec2-user/HEARTS_Replication/results\n",
      "Logs directory:    /home/ec2-user/HEARTS_Replication/logs\n",
      "\n",
      "‚úÖ Current directory: /home/ec2-user/HEARTS_Replication\n"
     ]
    }
   ],
   "source": [
    "# Setting up Working Directory\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SETTING UP WORKING DIRECTORY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Defining paths for model and results\n",
    "WORK_DIR = os.path.expanduser(\"~/HEARTS_Replication\")\n",
    "OUTPUT_DIR = os.path.join(WORK_DIR, \"model_output_albertv2\")\n",
    "RESULTS_DIR = os.path.join(WORK_DIR, \"results\")\n",
    "LOGS_DIR = os.path.join(WORK_DIR, \"logs\")\n",
    "\n",
    "# Creating directories\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Working directory: {WORK_DIR}\")\n",
    "print(f\"Output directory:  {OUTPUT_DIR}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"Logs directory:    {LOGS_DIR}\")\n",
    "\n",
    "# Changing to a working directory\n",
    "os.chdir(WORK_DIR)\n",
    "print(f\"\\n‚úÖ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ddc7ec",
   "metadata": {},
   "source": [
    "# Loading dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c8b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING EMGSD DATASET\n",
      "============================================================\n",
      "Downloading dataset from HuggingFace...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c514798e829467790fdeb302c304cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b125ec538043f492e88c6d66c8b800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed6ea08c90546fd9298f78f9eac4778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b19401e32fa4d5f9b69a34a270e6ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/45760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f17ef6b74543749af8cb36937ac14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Dataset loaded successfully!\n",
      "\n",
      "Dataset structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['stereotype_type', 'text', 'text_with_marker', 'category', 'data_source', 'label'],\n",
      "        num_rows: 45760\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['stereotype_type', 'text', 'text_with_marker', 'category', 'data_source', 'label'],\n",
      "        num_rows: 11441\n",
      "    })\n",
      "})\n",
      "\n",
      "Dataset sizes:\n",
      "  Train: 45,760 examples\n",
      "  Test:  11,441 examples\n",
      "  Total: 57,201 examples\n",
      "\n",
      "============================================================\n",
      "DATASET STRUCTURE\n",
      "============================================================\n",
      "Columns: ['stereotype_type', 'text', 'text_with_marker', 'category', 'data_source', 'label']\n",
      "\n",
      "First example:\n",
      "  stereotype_type: profession\n",
      "  text: The illustrator had tower hands....\n",
      "  text_with_marker: The illustrator had ===tower=== hands.\n",
      "  category: unrelated\n",
      "  data_source: stereoset_intrasentence\n",
      "  label: unrelated\n",
      "\n",
      "============================================================\n",
      "LABEL ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Category distribution:\n",
      "  Train: {'unrelated': 14992, 'stereotype': 15597, 'neutral': 15171}\n",
      "  Test:  {'stereotype': 3906, 'neutral': 3754, 'unrelated': 3781}\n",
      "\n",
      "‚úÖ Dataset loaded and analyzed!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LOADING EMGSD DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Loading dataset from HuggingFace\n",
    "print(\"Downloading dataset from HuggingFace...\")\n",
    "dataset = load_dataset(\"holistic-ai/EMGSD\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "print(\"\\nDataset structure:\")\n",
    "print(dataset)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train: {len(dataset['train']):,} examples\")\n",
    "print(f\"  Test:  {len(dataset['test']):,} examples\")\n",
    "print(f\"  Total: {len(dataset['train']) + len(dataset['test']):,} examples\")\n",
    "\n",
    "# Examining structure\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET STRUCTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Columns: {dataset['train'].column_names}\")\n",
    "\n",
    "print(\"\\nFirst example:\")\n",
    "first_example = dataset['train'][0]\n",
    "for key, value in first_example.items():\n",
    "    if key == 'text':\n",
    "        print(f\"  {key}: {value[:100]}...\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Checking label distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LABEL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Counting 'category' values\n",
    "train_categories = [ex['category'] for ex in dataset['train']]\n",
    "test_categories = [ex['category'] for ex in dataset['test']]\n",
    "\n",
    "train_dist = Counter(train_categories)\n",
    "test_dist = Counter(test_categories)\n",
    "\n",
    "print(\"\\nCategory distribution:\")\n",
    "print(f\"  Train: {dict(train_dist)}\")\n",
    "print(f\"  Test:  {dict(test_dist)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset loaded and analyzed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd6f9a",
   "metadata": {},
   "source": [
    "# Preparing Labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b5e09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARING LABELS FOR 3-CLASS CLASSIFICATION\n",
      "============================================================\n",
      "Label mapping: {'stereotype': 0, 'neutral': 1, 'unrelated': 2}\n",
      "\n",
      "Adding numerical labels to dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a09166efdee45629a5f2407f8db5a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a744cad0ce489b848cddfdba7c9a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VERIFICATION\n",
      "============================================================\n",
      "\n",
      "First 5 examples with labels:\n",
      "  1. category='unrelated   ' ‚Üí label=2 (unrelated)\n",
      "  2. category='unrelated   ' ‚Üí label=2 (unrelated)\n",
      "  3. category='unrelated   ' ‚Üí label=2 (unrelated)\n",
      "  4. category='unrelated   ' ‚Üí label=2 (unrelated)\n",
      "  5. category='unrelated   ' ‚Üí label=2 (unrelated)\n",
      "\n",
      "============================================================\n",
      "FINAL LABEL DISTRIBUTION\n",
      "============================================================\n",
      "stereotype   (label 0): Train=15,597 (34.1%), Test=3,906 (34.1%)\n",
      "neutral      (label 1): Train=15,171 (33.2%), Test=3,754 (32.8%)\n",
      "unrelated    (label 2): Train=14,992 (32.8%), Test=3,781 (33.0%)\n",
      "\n",
      "‚úÖ Dataset prepared with 3 classes\n",
      "   Total examples: 57,201\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PREPARING LABELS FOR 3-CLASS CLASSIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Defining label mapping, using the column \"category\"(stereotype, neutral, unrelated)\n",
    "label_to_id = {\n",
    "    'stereotype': 0,\n",
    "    'neutral': 1,\n",
    "    'unrelated': 2\n",
    "}\n",
    "\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "\n",
    "print(f\"Label mapping: {label_to_id}\")\n",
    "\n",
    "# Adding numerical labels to dataset\n",
    "def add_numeric_labels(examples):\n",
    "    examples['labels'] = [label_to_id[cat] for cat in examples['category']]\n",
    "    return examples\n",
    "\n",
    "print(\"\\nAdding numerical labels to dataset...\")\n",
    "dataset_with_labels = dataset.map(add_numeric_labels, batched=True)\n",
    "\n",
    "# Verifying labels\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nFirst 5 examples with labels:\")\n",
    "for i in range(5):\n",
    "    ex = dataset_with_labels['train'][i]\n",
    "    print(f\"  {i+1}. category='{ex['category']:12s}' ‚Üí label={ex['labels']} ({id_to_label[ex['labels']]})\")\n",
    "\n",
    "# Counting final label distribution\n",
    "train_labels = [ex['labels'] for ex in dataset_with_labels['train']]\n",
    "test_labels = [ex['labels'] for ex in dataset_with_labels['test']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL LABEL DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Printing label distribution\n",
    "for label_id in sorted(id_to_label.keys()):\n",
    "    label_name = id_to_label[label_id]\n",
    "    train_count = train_labels.count(label_id)\n",
    "    test_count = test_labels.count(label_id)\n",
    "    total = train_count + test_count\n",
    "    print(f\"{label_name:12s} (label {label_id}): Train={train_count:,} ({train_count/len(train_labels)*100:.1f}%), Test={test_count:,} ({test_count/len(test_labels)*100:.1f}%)\")\n",
    "\n",
    "num_labels = 3\n",
    "print(f\"\\n‚úÖ Dataset prepared with {num_labels} classes\")\n",
    "print(f\"   Total examples: {len(dataset_with_labels['train']) + len(dataset_with_labels['test']):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bf21d8",
   "metadata": {},
   "source": [
    "# Loading the ALBERT-V2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02578a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING ALBERT-V2 MODEL\n",
      "============================================================\n",
      "Model: albert/albert-base-v2\n",
      "Loading from HuggingFace Hub...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce05dfd7b651409e91de41f64933a2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074f5710066849988c5d2ffce16284b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f8de1b216e480d8fc7b055c972910d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad92ecdcdfe545b086e819a4be2645d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenizer loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e904d9786074a0da5bbe6b5456ddca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded\n",
      "\n",
      "============================================================\n",
      "MODEL CONFIGURATION\n",
      "============================================================\n",
      "Base model:       albert/albert-base-v2\n",
      "Number of labels: 3\n",
      "Label mapping:    {0: 'stereotype', 1: 'neutral', 2: 'unrelated'}\n",
      "Max length:       512 tokens (HEARTS paper uses 512)\n",
      "\n",
      "‚ö†Ô∏è  Expected warning above: 'classifier.bias' and 'classifier.weight' are\n",
      "   newly initialized - this is NORMAL for fine-tuning!\n",
      "\n",
      "‚úÖ ALBERT-V2 model ready for training\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LOADING ALBERT-V2 MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Defining model path\n",
    "model_path = 'albert/albert-base-v2'\n",
    "print(f\"Model: {model_path}\")\n",
    "print(f\"Loading from HuggingFace Hub...\\n\")\n",
    "\n",
    "# Loading tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "print(\"‚úÖ Tokenizer loaded\")\n",
    "\n",
    "# Loading model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "print(\"‚úÖ Model loaded\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Base model:       {model_path}\")\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "print(f\"Label mapping:    {id_to_label}\")\n",
    "print(f\"Max length:       512 tokens (HEARTS paper uses 512)\")\n",
    "\n",
    "# Checking for expected warning\n",
    "print(\"\\n‚ö†Ô∏è  Expected warning above: 'classifier.bias' and 'classifier.weight' are\")\n",
    "print(\"   newly initialized, this is NORMAL for fine-tuning!\")\n",
    "\n",
    "print(\"\\n‚úÖ ALBERT-V2 model ready for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c8e274",
   "metadata": {},
   "source": [
    "# Tokenizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f5afe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOKENIZING DATASET\n",
      "============================================================\n",
      "Tokenizing training set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72479c4bec1d4d54afceecf04925e157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train tokenized: 45,760 examples\n",
      "Tokenizing test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e22b577b8f451cb1e3446c19e23c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test tokenized: 11,441 examples\n",
      "\n",
      "============================================================\n",
      "TOKENIZED DATA SAMPLE\n",
      "============================================================\n",
      "Keys in tokenized example: ['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Input IDs length: 48\n",
      "Label: 2 (unrelated)\n",
      "\n",
      "‚úÖ Tokenization complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TOKENIZING DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Defining tokenization function (max_length=512, as prescribed by King et al.(2024))\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "print(\"Tokenizing training set...\")\n",
    "# Removing columns not needed for training\n",
    "columns_to_remove = ['stereotype_type', 'text', 'text_with_marker', 'category', 'data_source', 'label']\n",
    "\n",
    "# Implementing the tokenization function\n",
    "tokenized_train = dataset_with_labels['train'].map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    remove_columns=columns_to_remove\n",
    ")\n",
    "print(f\"‚úÖ Train tokenized: {len(tokenized_train):,} examples\")\n",
    "\n",
    "print(\"Tokenizing test set...\")\n",
    "tokenized_test = dataset_with_labels['test'].map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    remove_columns=columns_to_remove\n",
    ")\n",
    "print(f\"‚úÖ Test tokenized: {len(tokenized_test):,} examples\")\n",
    "\n",
    "# Verifying tokenized data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOKENIZED DATA SAMPLE\")\n",
    "print(\"=\"*60)\n",
    "print(\"Keys in tokenized example:\", list(tokenized_train[0].keys()))\n",
    "print(f\"Input IDs length: {len(tokenized_train[0]['input_ids'])}\")\n",
    "print(f\"Label: {tokenized_train[0]['labels']} ({id_to_label[tokenized_train[0]['labels']]})\")\n",
    "\n",
    "print(\"\\n‚úÖ Tokenization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa692bd",
   "metadata": {},
   "source": [
    "# Creating Train/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98df3fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING TRAIN/VALIDATION SPLIT\n",
      "============================================================\n",
      "Splitting training set (80% train, 20% validation)...\n",
      "\n",
      "============================================================\n",
      "FINAL DATASET SPLITS\n",
      "============================================================\n",
      "Training set:   36,608 examples\n",
      "Validation set: 9,152 examples\n",
      "Test set:       11,441 examples\n",
      "Total:          57,201 examples\n",
      "\n",
      "Training steps:\n",
      "  Steps per epoch: ~572\n",
      "  Total steps (6 epochs): ~3432\n",
      "\n",
      "‚úÖ Dataset splits ready for training!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CREATING TRAIN/VALIDATION SPLIT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Spliting train into train/val (80/20 split, matching HEARTS paper)\n",
    "print(\"Splitting training set (80% train, 20% validation)...\")\n",
    "train_val_split = tokenized_train.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "tokenized_train_final = train_val_split['train']\n",
    "tokenized_val = train_val_split['test']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL DATASET SPLITS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training set:   {len(tokenized_train_final):,} examples\")\n",
    "print(f\"Validation set: {len(tokenized_val):,} examples\")\n",
    "print(f\"Test set:       {len(tokenized_test):,} examples\")\n",
    "print(f\"Total:          {len(tokenized_train_final) + len(tokenized_val) + len(tokenized_test):,} examples\")\n",
    "\n",
    "# Calculating steps per epoch\n",
    "steps_per_epoch = len(tokenized_train_final) // 64  # batch_size=64\n",
    "total_steps = steps_per_epoch * 6  # 6 epochs\n",
    "\n",
    "print(f\"\\nTraining steps:\")\n",
    "print(f\"  Steps per epoch: ~{steps_per_epoch}\")\n",
    "print(f\"  Total steps (6 epochs): ~{total_steps}\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset splits ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd6acd2",
   "metadata": {},
   "source": [
    "# Defining evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffabb6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEFINING EVALUATION METRICS\n",
      "============================================================\n",
      "‚úÖ Metrics defined:\n",
      "   - Accuracy\n",
      "   - Precision (macro)\n",
      "   - Recall (macro)\n",
      "   - F1 Score (macro)\n",
      "   - Balanced Accuracy\n",
      "\n",
      "‚úÖ Evaluation metrics ready!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DEFINING EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Defining compute_metrics function, similar to the code provided by King et al.(2024)\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute metrics matching HEARTS paper:\n",
    "    - Accuracy\n",
    "    - Precision (macro)\n",
    "    - Recall (macro)\n",
    "    - F1 (macro)\n",
    "    - Balanced accuracy\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Calculating metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='macro'\n",
    "    )\n",
    "    balanced_acc = balanced_accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"balanced_accuracy\": balanced_acc\n",
    "    }\n",
    "\n",
    "# Prining metrics\n",
    "print(\"‚úÖ Metrics defined:\")\n",
    "print(\"   - Accuracy\")\n",
    "print(\"   - Precision (macro)\")\n",
    "print(\"   - Recall (macro)\")\n",
    "print(\"   - F1 Score (macro)\")\n",
    "print(\"   - Balanced Accuracy\")\n",
    "\n",
    "print(\"\\n‚úÖ Evaluation metrics ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be22538e",
   "metadata": {},
   "source": [
    "# Defining Training Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "face3497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURING TRAINING ARGUMENTS\n",
      "============================================================\n",
      "Random seed set to: 42\n",
      "\n",
      "============================================================\n",
      "TRAINING CONFIGURATION\n",
      "============================================================\n",
      "Model:           albert/albert-base-v2\n",
      "Epochs:          6\n",
      "Batch size:      64\n",
      "Learning rate:   2e-05\n",
      "Weight decay:    0.01\n",
      "Max length:      512 tokens\n",
      "FP16:            True\n",
      "Seed:            42\n",
      "\n",
      "Output directory: /home/ec2-user/HEARTS_Replication/model_output_albertv2/emgsd_trained\n",
      "\n",
      "‚úÖ Training arguments configured\n"
     ]
    }
   ],
   "source": [
    "# Configuring Training, as precribed by King et al. (2024)\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURING TRAINING ARGUMENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Setting random seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "# Defining training arguments, as precribed by King et al. (2024)\n",
    "training_args = TrainingArguments(\n",
    "    # Output\n",
    "    output_dir=os.path.join(OUTPUT_DIR, \"emgsd_trained\"),\n",
    "    logging_dir=LOGS_DIR,\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    num_train_epochs=6,                    \n",
    "    learning_rate=2e-5,                    \n",
    "    per_device_train_batch_size=64,       \n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,                     \n",
    "    \n",
    "    # Evaluation and saving\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=1,                    \n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=100,\n",
    "    \n",
    "    # Performance\n",
    "    fp16=True,                             \n",
    "    \n",
    "    # Reproducibility\n",
    "    seed=seed,\n",
    "    \n",
    "    # Disabling external logging\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model:           albert/albert-base-v2\")\n",
    "print(f\"Epochs:          {training_args.num_train_epochs}\")\n",
    "print(f\"Batch size:      {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Learning rate:   {training_args.learning_rate}\")\n",
    "print(f\"Weight decay:    {training_args.weight_decay}\")\n",
    "print(f\"Max length:      512 tokens\")\n",
    "print(f\"FP16:            {training_args.fp16}\")\n",
    "print(f\"Seed:            {training_args.seed}\")\n",
    "print(f\"\\nOutput directory: {training_args.output_dir}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training arguments configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c1f1f",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7665c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INITIALIZING TRAINER\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31878/4288036437.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer initialized\n",
      "\n",
      "============================================================\n",
      "HARDWARE CHECK\n",
      "============================================================\n",
      "‚úÖ GPU: Tesla T4\n",
      "‚úÖ GPU Memory: 15.64 GB\n",
      "‚úÖ FP16 enabled: Faster training\n",
      "\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Training samples: 36,608\n",
      "Validation samples: 9,152\n",
      "Epochs: 6\n",
      "Steps per epoch: ~572\n",
      "Total steps: ~3432\n",
      "\n",
      "‚è±Ô∏è  Estimated time: 30-60 minutes on GPU\n",
      "    (You can monitor progress below)\n",
      "============================================================\n",
      "\n",
      "üöÄ Training started...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3432' max='3432' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3432/3432 14:39, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.742800</td>\n",
       "      <td>0.573281</td>\n",
       "      <td>0.727928</td>\n",
       "      <td>0.730601</td>\n",
       "      <td>0.728041</td>\n",
       "      <td>0.725180</td>\n",
       "      <td>0.728041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>0.480083</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.783649</td>\n",
       "      <td>0.785572</td>\n",
       "      <td>0.783931</td>\n",
       "      <td>0.785572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.369000</td>\n",
       "      <td>0.451524</td>\n",
       "      <td>0.809003</td>\n",
       "      <td>0.810541</td>\n",
       "      <td>0.809099</td>\n",
       "      <td>0.808734</td>\n",
       "      <td>0.809099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.458666</td>\n",
       "      <td>0.815669</td>\n",
       "      <td>0.813851</td>\n",
       "      <td>0.815807</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.815807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.819056</td>\n",
       "      <td>0.820491</td>\n",
       "      <td>0.819289</td>\n",
       "      <td>0.819004</td>\n",
       "      <td>0.819289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.552944</td>\n",
       "      <td>0.815450</td>\n",
       "      <td>0.816404</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.815851</td>\n",
       "      <td>0.815642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ TRAINING COMPLETED!\n",
      "============================================================\n",
      "Total time: 14.68 minutes (0.24 hours)\n",
      "Average time per epoch: 2.45 minutes\n",
      "\n",
      "============================================================\n",
      "SAVING MODEL\n",
      "============================================================\n",
      "‚úÖ Model saved to: /home/ec2-user/HEARTS_Replication/model_output_albertv2/emgsd_trained\n",
      "\n",
      "============================================================\n",
      "TRAINING METADATA\n",
      "============================================================\n",
      "model_path               : albert/albert-base-v2\n",
      "num_labels               : 3\n",
      "epochs                   : 6\n",
      "batch_size               : 64\n",
      "learning_rate            : 2e-05\n",
      "weight_decay             : 0.01\n",
      "max_length               : 512\n",
      "training_time_minutes    : 14.676026300589244\n",
      "train_size               : 36608\n",
      "val_size                 : 9152\n",
      "test_size                : 11441\n",
      "seed                     : 42\n",
      "\n",
      "‚úÖ HEARTS REPLICATION TRAINING COMPLETE!\n",
      "   Ready for evaluation...\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"INITIALIZING TRAINER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initializing Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_train_final,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized\")\n",
    "\n",
    "# Checking GPU\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HARDWARE CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"‚úÖ GPU: {gpu_name}\")\n",
    "    print(f\"‚úÖ GPU Memory: {gpu_memory:.2f} GB\")\n",
    "    print(f\"‚úÖ FP16 enabled: Faster training\")\n",
    "else:\n",
    "    print(\"‚ùå NO GPU DETECTED!\")\n",
    "    print(\"   Training will be very slow\")\n",
    "\n",
    "# Beginning Training\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training samples: {len(tokenized_train_final):,}\")\n",
    "print(f\"Validation samples: {len(tokenized_val):,}\")\n",
    "print(f\"Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Steps per epoch: ~{len(tokenized_train_final) // training_args.per_device_train_batch_size}\")\n",
    "print(f\"Total steps: ~{(len(tokenized_train_final) // training_args.per_device_train_batch_size) * training_args.num_train_epochs}\")\n",
    "print(f\"\\n‚è±Ô∏è  Estimated time: 30-60 minutes on GPU\")\n",
    "print(f\"    (You can monitor progress below)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Recording start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Training the model\n",
    "print(\"üöÄ Training started...\\n\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Calculating training time using start_time\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Displaying when training is completed\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total time: {training_time/60:.2f} minutes ({training_time/3600:.2f} hours)\")\n",
    "print(f\"Average time per epoch: {training_time/training_args.num_train_epochs/60:.2f} minutes\")\n",
    "\n",
    "# Saving the model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_save_path = os.path.join(OUTPUT_DIR, \"emgsd_trained\")\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {model_save_path}\")\n",
    "\n",
    "# Storing training metadata\n",
    "training_metadata = {\n",
    "    'model_path': 'albert/albert-base-v2',\n",
    "    'num_labels': num_labels,\n",
    "    'label_mapping': label_to_id,\n",
    "    'epochs': training_args.num_train_epochs,\n",
    "    'batch_size': training_args.per_device_train_batch_size,\n",
    "    'learning_rate': training_args.learning_rate,\n",
    "    'weight_decay': training_args.weight_decay,\n",
    "    'max_length': 512,\n",
    "    'training_time_minutes': training_time/60,\n",
    "    'train_size': len(tokenized_train_final),\n",
    "    'val_size': len(tokenized_val),\n",
    "    'test_size': len(tokenized_test),\n",
    "    'seed': seed\n",
    "}\n",
    "\n",
    "# Printing training metadata\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING METADATA\")\n",
    "print(\"=\"*60)\n",
    "for key, value in training_metadata.items():\n",
    "    if key != 'label_mapping':\n",
    "        print(f\"{key:25s}: {value}\")\n",
    "\n",
    "print(\"\\n‚úÖ HEARTS REPLICATION TRAINING COMPLETE!\")\n",
    "print(\"   Ready for evaluation...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba371b",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feae277f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATING ON TEST SET\n",
      "============================================================\n",
      "Running evaluation on test set...\n",
      "(This will take 1-2 minutes)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation complete!\n",
      "\n",
      "============================================================\n",
      "TEST SET RESULTS\n",
      "============================================================\n",
      "epoch                    : 6.0000\n",
      "eval_accuracy            : 0.8118\n",
      "eval_balanced_accuracy   : 0.8127\n",
      "eval_f1                  : 0.8128\n",
      "eval_loss                : 0.5232\n",
      "eval_precision           : 0.8146\n",
      "eval_recall              : 0.8127\n",
      "eval_runtime             : 13.9945\n",
      "eval_samples_per_second  : 817.5340\n",
      "eval_steps_per_second    : 12.7910\n",
      "\n",
      "============================================================\n",
      "GENERATING PREDICTIONS FOR ANALYSIS\n",
      "============================================================\n",
      "‚úÖ Predictions generated\n",
      "   Total predictions: 11,441\n",
      "\n",
      "============================================================\n",
      "FINAL METRICS\n",
      "============================================================\n",
      "Accuracy:        0.8118 (81.18%)\n",
      "F1 (Macro):      0.8128\n",
      "F1 (Weighted):   0.8123\n",
      "\n",
      "‚úÖ Test set evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EVALUATING ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Beginning evaluation on test set\n",
    "print(\"Running evaluation on test set...\")\n",
    "print(\"(This will take 1-2 minutes)\\n\")\n",
    "\n",
    "eval_results = trainer.evaluate(tokenized_test)\n",
    "\n",
    "print(\"‚úÖ Evaluation complete!\\n\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for key, value in sorted(eval_results.items()):\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key:25s}: {value:.4f}\")\n",
    "\n",
    "# Obtaining predictions for detailed analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING PREDICTIONS FOR ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "true_labels = predictions.label_ids\n",
    "pred_probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=-1).numpy()\n",
    "\n",
    "print(f\"‚úÖ Predictions generated\")\n",
    "print(f\"   Total predictions: {len(pred_labels):,}\")\n",
    "\n",
    "# Calculating key metrics\n",
    "final_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "final_f1_macro = f1_score(true_labels, pred_labels, average='macro')\n",
    "final_f1_weighted = f1_score(true_labels, pred_labels, average='weighted')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:        {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "print(f\"F1 (Macro):      {final_f1_macro:.4f}\")\n",
    "print(f\"F1 (Weighted):   {final_f1_weighted:.4f}\")\n",
    "\n",
    "# Storing results\n",
    "replication_results = {\n",
    "    'accuracy': final_accuracy,\n",
    "    'f1_macro': final_f1_macro,\n",
    "    'f1_weighted': final_f1_weighted,\n",
    "    'precision': eval_results.get('eval_precision', 0),\n",
    "    'recall': eval_results.get('eval_recall', 0),\n",
    "    'balanced_accuracy': eval_results.get('eval_balanced_accuracy', 0)\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ Test set evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c2a1a2",
   "metadata": {},
   "source": [
    "# Comparing with King et al. (2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "144a7843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPARISON WITH HEARTS PAPER (F1 SCORE)\n",
      "============================================================\n",
      "\n",
      "Paper F1 Score:        0.8150   (81.50%)\n",
      "Your Model F1 Score:   0.8128   (81.28%)\n",
      "Difference:            0.22%\n",
      "\n",
      "‚úÖ SUCCESS! The replication is within ¬±5% of the model trained by King et al. (2024).\n",
      "\n",
      "‚úÖ F1 comparison complete!\n"
     ]
    }
   ],
   "source": [
    "# Comparing F1 Score of the trained model against the model trained by King et al. (2024)\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARISON WITH HEARTS FRAMEWORK (F1 SCORE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# The F1 Score reported by King et al. (2024)\n",
    "paper_f1 = 0.815   # 81.5%\n",
    "\n",
    "# The F1 Score of the model I trained\n",
    "your_f1 = eval_results[\"eval_f1\"]\n",
    "\n",
    "# Computing difference between the two F1 scores\n",
    "difference = abs(paper_f1 - your_f1)\n",
    "difference_pct = difference * 100\n",
    "\n",
    "# Defining the threshold for replication success (¬±5%), as per the coursework guidelines\n",
    "threshold = 0.05\n",
    "success = difference <= threshold\n",
    "\n",
    "print(f\"\\nPaper F1 Score:        {paper_f1:.4f}   ({paper_f1*100:.2f}%)\")\n",
    "print(f\"Your Model F1 Score:   {your_f1:.4f}   ({your_f1*100:.2f}%)\")\n",
    "print(f\"Difference:            {difference_pct:.2f}%\")\n",
    "\n",
    "if success:\n",
    "    print(\"\\n‚úÖ SUCCESS! The replication is within ¬±5% of the model trained by King et al. (2024).\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: The replication differs by more than ¬±5%.\")\n",
    "    print(\"   Check training setup, tokenization, or label mapping.\")\n",
    "\n",
    "print(\"\\n‚úÖ F1 comparison complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "819892d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metrics obtained by King et al. (2024)\n",
    "paper_metrics = {\n",
    "    \"accuracy\": 0.80, # Authors reported an accuracy of over 80 per-cent\n",
    "    \"precision\": 0.82,\n",
    "    \"recall\": 0.82,\n",
    "    \"f1\": 0.815   # reported macro-F1\n",
    "}\n",
    "\n",
    "# Metrics obtained by replication\n",
    "our_metrics = {\n",
    "    \"accuracy\": replication_results[\"accuracy\"],\n",
    "    \"precision\": replication_results[\"precision\"],\n",
    "    \"recall\": replication_results[\"recall\"],\n",
    "    \"f1\": replication_results[\"f1_macro\"]\n",
    "}\n",
    "\n",
    "metrics = list(paper_metrics.keys())\n",
    "paper_vals = [paper_metrics[m] for m in metrics]\n",
    "our_vals   = [our_metrics[m] for m in metrics]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "# Plotting a bar plot contrasting paper metrics and the metrics obtained through replication\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(x - width/2, paper_vals, width, label='King et al.(2024)', alpha=0.8)\n",
    "plt.bar(x + width/2, our_vals, width, label='My Replication', alpha=0.8)\n",
    "\n",
    "plt.xticks(x, [m.upper() for m in metrics])\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"HEARTS Paper vs Our Replication\")\n",
    "plt.ylim(0.70, 0.90)\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
